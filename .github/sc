!pip install transformers
!pip install dateparser
!pip install hanlp
!pip install regex
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import dateparser
import re
import hanlp
from datetime import datetime
# ===== ä¸€ã€åˆå§‹åŒ–å…©å¥—æ¨¡å‹ =====
# 1. ckiplab NER
model_name = "ckiplab/bert-base-chinese-ner"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)
ner = pipeline("ner", model=model, tokenizer=tokenizer, grouped_entities=True)

# 2. HanLP
hanlp_pipeline = hanlp.load('FINE_ELECTRA_SMALL_ZH')
# ===== äºŒã€åˆ†æå‡½å¼ =====

def normalize_time(time_str, base_year=None):
    # æ­£è¦åŒ–ã€Œä¸‹åˆ3é»ã€ç­‰ç‚º24å°æ™‚åˆ¶
    if not time_str:
        return None
    year = base_year or datetime.now().year
    # è£œå¹´ä»½
    time_str = re.sub(r"^(\d{1,2})æœˆ", f"{year}å¹´\\1æœˆ", time_str)
    # AM/PMè™•ç†
    match = re.search(r"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\d{1,2})é»åŠ?", time_str)
    if match:
        h = int(match.group(2))
        if match.group(1) in ["ä¸‹åˆ", "æ™šä¸Š", "å‚æ™š"]:
            if h < 12:
                h += 12
        elif match.group(1) in ["ä¸­åˆ"]:
            h = 12
        elif match.group(1) in ["å‡Œæ™¨"]:
            if h == 12:
                h = 0
        # æ›¿æ›åŸæœ¬çš„æ™‚é–“
        time_str = re.sub(r"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\d{1,2})é»åŠ?", f"{h:02d}:00", time_str)
    dt = dateparser.parse(time_str, languages=['zh'])
    return dt

def extract_location(sentence, hanlp_out):
    # å…ˆç”¨ HanLP
    if 'location' in hanlp_out and hanlp_out['location']:
        return hanlp_out['location'][0][0]
    # è‹¥ HanLPæ²’æŠ“åˆ°ï¼Œç”¨åœ°é»é—œéµå­—æ­£å‰‡è£œ
    # é—œéµå­—å¯ä¾éœ€æ±‚è‡ªè¡Œæ“´å……
    location_keywords = r"(è»Šç«™|å¤§æ¨“|é¤¨|ä¸­å¿ƒ|é†«é™¢|å…¬åœ’|å­¸æ ¡|é£¯åº—|è¶…å¸‚|ç™¾è²¨|åœ–æ›¸é¤¨|æ©Ÿå ´|é«”è‚²é¤¨|æ·é‹ç«™|ç«è»Šç«™|å•†å ´|å°åŒ—è»Šç«™|å·¥å­¸å¤§æ¨“|å¤§æ¨“|æ—©é¤åº—)"
    # æŠ“ã€Œ2~8å­—ã€+é—œéµå­—ï¼Œå¦‚ã€Œå°åŒ—è»Šç«™ã€ã€ã€Œä¿¡ç¾©å¤§æ¨“ã€
    loc_match = re.search(r"([\u4e00-\u9fa5]{2,8}" + location_keywords + ")", sentence)
    if loc_match:
        return loc_match.group(0)
    return ""

def clean_event_desc(sentence, time_str, location):
    desc = sentence
    if time_str:
        desc = desc.replace(time_str, "")
    if location:
        desc = desc.replace(location, "")
    # å»æ‰ã€Œæˆ‘åœ¨ã€ã€Œè¦åˆ°ã€ã€ŒåƒåŠ ã€ç­‰åŠ©è©/å‹•è©å‰ç¶´
    desc = re.sub(r"^[æˆ‘ä½ ä»–å¥¹åœ¨è¦å»åˆ°æ–¼åƒåŠ å‰å¾€]+", "", desc)
    desc = desc.strip("ï¼Œã€‚ ")
    return desc
# ===== ä¸‰ã€ä¸»æµç¨‹ (é›™æ¨¡å‹èåˆ) =====
sentence = "æˆ‘åœ¨6æœˆ10æ—¥ä¸‹åˆ3é»è¦åˆ°å°åŒ—è»Šç«™åƒåŠ è«–æ–‡å£è©¦"

# 1. transformers NER é æ¸¬
ner_results = ner(sentence)

# 2. HanLP é æ¸¬
hanlp_time, hanlp_location = extract_by_hanlp(sentence)

# 3. æ­£å‰‡æŠ“æ™‚é–“
regex_time = extract_time_regex(sentence)

# 4. NERæŠ“æ™‚é–“ã€åœ°é»
ner_time = extract_time_ner(sentence, ner_results)
ner_location = extract_location_ner(ner_results)

# ===== å››ã€æ¡ç”¨ã€Œæœ€ç©©å®šã€ä¾†æºï¼šå„ªå…ˆé †åº HanLP > æ­£å‰‡ > NER =====
# æ™‚é–“
time_str = hanlp_time or regex_time or ner_time
# åœ°é»
location = hanlp_location or ner_location

# äº‹ä»¶æè¿°ï¼ˆå¾åŸæ–‡ç§»é™¤æ™‚é–“ã€åœ°é»ï¼‰
event_desc = extract_event_desc(sentence, time_str, location)

# è§£ææ™‚é–“
parsed_time = dateparser.parse(time_str, languages=['zh'])

# ===== äº”ã€æœ€çµ‚è¼¸å‡º =====
print("âœ… æ“·å–çµæœï¼š")
print("ğŸ•’ æ™‚é–“ï¼š", parsed_time, "ï½œåŸæ–‡ï¼š", time_str)
print("ğŸ“ åœ°é»ï¼š", location)
print("ğŸ“ äº‹ä»¶æè¿°ï¼š", event_desc)



# è¼‰å…¥ HanLP
hanlp_pipeline = hanlp.load('FINE_ELECTRA_SMALL_ZH')

def extract_time_regex(sentence):
    """ç”¨æ­£å‰‡å¼è£œæ‰ä¸­æ–‡æ™‚é–“"""
    patterns = [
        r"\d{1,2}æœˆ\d{1,2}æ—¥[ä¸Šä¸‹]åˆ\d{1,2}é»åŠ?",
        r"\d{1,2}æœˆ\d{1,2}æ—¥\d{1,2}é»åŠ?",
        r"\d{1,2}æœˆ\d{1,2}æ—¥\d{1,2}é»",
        r"\d{1,2}æœˆ\d{1,2}æ—¥",
        r"[ä¸Šä¸‹]åˆ\d{1,2}é»åŠ?",
        r"\d{1,2}é»åŠ?",
        r"\d{1,2}é»",
    ]
    regex = "|".join(patterns)
    match = re.search(regex, sentence)
    if match:
        return match.group()
    return ""

def normalize_time(time_str, base_year=None):
    """å°‡æ™‚é–“æ–‡å­—è½‰æˆ datetime"""
    if not time_str:
        return None
    year = base_year or datetime.now().year
    time_str = re.sub(r"^(\d{1,2})æœˆ", f"{year}å¹´\\1æœˆ", time_str)
    # è½‰æ›ä¸‹åˆã€æ™šä¸Šç­‰è©å½™
    match = re.search(r"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\d{1,2})é»(åŠ)?", time_str)
    if match:
        h = int(match.group(2))
        if match.group(1) in ["ä¸‹åˆ", "æ™šä¸Š", "å‚æ™š"] and h < 12:
            h += 12
        elif match.group(1) == "ä¸­åˆ":
            h = 12
        elif match.group(1) == "å‡Œæ™¨" and h == 12:
            h = 0
        m = "30" if match.group(3) else "00"
        time_str = re.sub(r"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\d{1,2})é»(åŠ)?", f"{h:02d}:{m}", time_str)
    dt = dateparser.parse(time_str, languages=['zh'])
    return dt

def extract_location(sentence, hanlp_out):
    """åœ°é»æŠ½å–ï¼šHanLP + è‡ªè¨‚é—œéµå­—å¾Œç¶´"""
    if 'location' in hanlp_out and hanlp_out['location']:
        return hanlp_out['location'][0][0]
    location_keywords = r"(è»Šç«™|å¤§æ¨“|é¤¨|ä¸­å¿ƒ|é†«é™¢|å…¬åœ’|å­¸æ ¡|é£¯åº—|è¶…å¸‚|ç™¾è²¨|åœ–æ›¸é¤¨|æ©Ÿå ´|é«”è‚²é¤¨|æ·é‹ç«™|ç«è»Šç«™|å•†å ´|å°åŒ—è»Šç«™)"
    loc_match = re.search(r"[\u4e00-\u9fa5]{2,10}" + location_keywords, sentence)
    if loc_match:
        return loc_match.group(0)
    return ""

def clean_event_desc(sentence, time_str, location):
    """ç§»é™¤æ™‚é–“èˆ‡åœ°é»ï¼Œç•™ä¸‹äº‹ä»¶æè¿°"""
    desc = sentence
    if time_str:
        desc = desc.replace(time_str, "")
    if location:
        desc = desc.replace(location, "")
    desc = re.sub(r"^[æˆ‘ä½ ä»–å¥¹åœ¨è¦å»åˆ°æ–¼åƒåŠ å‰å¾€]+", "", desc)
    return desc.strip("ï¼Œã€‚ ")

def extract_event(sentence):
    """ä¸»æŠ½å–æµç¨‹ï¼šæ™‚é–“ã€åœ°é»ã€æè¿°"""
    hanlp_out = hanlp_pipeline(sentence)

    time_str = hanlp_out['time'][0][0] if 'time' in hanlp_out and hanlp_out['time'] else extract_time_regex(sentence)
    parsed_time = normalize_time(time_str)

    location = extract_location(sentence, hanlp_out)
    event_desc = clean_event_desc(sentence, time_str, location)

    return {
        "æ™‚é–“åŸæ–‡": time_str,
        "æ™‚é–“è§£æ": parsed_time,
        "åœ°é»": location,
        "äº‹ä»¶æè¿°": event_desc
    }

# ==== æ¸¬è©¦ ====
sentence = "æˆ‘åœ¨6æœˆ10æ—¥ä¸‹åˆ3é»è¦åˆ°å°åŒ—è»Šç«™åƒåŠ è«–æ–‡å£è©¦"
event_info = extract_event(sentence)

print("âœ… æ“·å–çµæœï¼š")
print("ğŸ•’ æ™‚é–“ï¼š", event_info["æ™‚é–“è§£æ"], "ï½œåŸæ–‡ï¼š", event_info["æ™‚é–“åŸæ–‡"])
print("ğŸ“ åœ°é»ï¼š", event_info["åœ°é»"])
print("ğŸ“ äº‹ä»¶æè¿°ï¼š", event_info["äº‹ä»¶æè¿°"])
