{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install dateparser\n",
        "!pip install hanlp\n",
        "!pip install regex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ACCXwuD3XnRQ",
        "outputId": "b0f9c7f4-541b-4e18-e140-6ad6f9224550"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n",
            "Requirement already satisfied: hanlp in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Requirement already satisfied: hanlp-common>=0.0.23 in /usr/local/lib/python3.11/dist-packages (from hanlp) (0.0.23)\n",
            "Requirement already satisfied: hanlp-downloader in /usr/local/lib/python3.11/dist-packages (from hanlp) (0.0.25)\n",
            "Requirement already satisfied: hanlp-trie>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from hanlp) (0.0.5)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from hanlp) (12.0.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from hanlp) (0.2.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from hanlp) (3.1.0)\n",
            "Requirement already satisfied: toposort==1.5 in /usr/local/lib/python3.11/dist-packages (from hanlp) (1.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from hanlp) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from hanlp) (4.52.4)\n",
            "Requirement already satisfied: phrasetree>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from hanlp-common>=0.0.23->hanlp) (0.0.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->hanlp) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->hanlp) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1.1->hanlp) (4.67.1)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->hanlp) (12.575.51)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.1.1->hanlp) (1.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->hanlp) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.1.1->hanlp) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.1.1->hanlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.1.1->hanlp) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.1.1->hanlp) (2025.4.26)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "import dateparser\n",
        "import re\n",
        "import hanlp\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "3hrZDjzxXz7_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ä¸€ã€åˆå§‹åŒ–å…©å¥—æ¨¡å‹ =====\n",
        "# 1. ckiplab NER\n",
        "model_name = \"ckiplab/bert-base-chinese-ner\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
        "\n",
        "# 2. HanLP\n",
        "hanlp_pipeline = hanlp.load('FINE_ELECTRA_SMALL_ZH')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jono923mX5gk",
        "outputId": "46fe9813-314c-465e-87c3-3ac41524c8b7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following layers were not sharded: bert.encoder.layer.*.attention.self.key.bias, bert.encoder.layer.*.attention.self.key.weight, bert.embeddings.token_type_embeddings.weight, bert.encoder.layer.*.attention.self.query.weight, bert.embeddings.position_embeddings.weight, bert.encoder.layer.*.output.dense.weight, classifier.bias, bert.encoder.layer.*.attention.output.dense.bias, bert.embeddings.word_embeddings.weight, bert.encoder.layer.*.attention.output.LayerNorm.weight, bert.embeddings.LayerNorm.weight, bert.embeddings.LayerNorm.bias, bert.encoder.layer.*.attention.self.query.bias, classifier.weight, bert.encoder.layer.*.output.LayerNorm.weight, bert.encoder.layer.*.attention.self.value.bias, bert.encoder.layer.*.output.dense.bias, bert.encoder.layer.*.attention.output.dense.weight, bert.encoder.layer.*.attention.self.value.weight, bert.encoder.layer.*.intermediate.dense.weight, bert.encoder.layer.*.output.LayerNorm.bias, bert.encoder.layer.*.intermediate.dense.bias, bert.encoder.layer.*.attention.output.LayerNorm.bias\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== äºŒã€åˆ†æå‡½å¼ =====\n",
        "\n",
        "def normalize_time(time_str, base_year=None):\n",
        "    # æ­£è¦åŒ–ã€Œä¸‹åˆ3é»ã€ç­‰ç‚º24å°æ™‚åˆ¶\n",
        "    if not time_str:\n",
        "        return None\n",
        "    year = base_year or datetime.now().year\n",
        "    # è£œå¹´ä»½\n",
        "    time_str = re.sub(r\"^(\\d{1,2})æœˆ\", f\"{year}å¹´\\\\1æœˆ\", time_str)\n",
        "    # AM/PMè™•ç†\n",
        "    match = re.search(r\"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\\d{1,2})é»åŠ?\", time_str)\n",
        "    if match:\n",
        "        h = int(match.group(2))\n",
        "        if match.group(1) in [\"ä¸‹åˆ\", \"æ™šä¸Š\", \"å‚æ™š\"]:\n",
        "            if h < 12:\n",
        "                h += 12\n",
        "        elif match.group(1) in [\"ä¸­åˆ\"]:\n",
        "            h = 12\n",
        "        elif match.group(1) in [\"å‡Œæ™¨\"]:\n",
        "            if h == 12:\n",
        "                h = 0\n",
        "        # æ›¿æ›åŸæœ¬çš„æ™‚é–“\n",
        "        time_str = re.sub(r\"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\\d{1,2})é»åŠ?\", f\"{h:02d}:00\", time_str)\n",
        "    dt = dateparser.parse(time_str, languages=['zh'])\n",
        "    return dt\n",
        "\n",
        "def extract_location(sentence, hanlp_out):\n",
        "    # å…ˆç”¨ HanLP\n",
        "    if 'location' in hanlp_out and hanlp_out['location']:\n",
        "        return hanlp_out['location'][0][0]\n",
        "    # è‹¥ HanLPæ²’æŠ“åˆ°ï¼Œç”¨åœ°é»é—œéµå­—æ­£å‰‡è£œ\n",
        "    # é—œéµå­—å¯ä¾éœ€æ±‚è‡ªè¡Œæ“´å……\n",
        "    location_keywords = r\"(è»Šç«™|å¤§æ¨“|é¤¨|ä¸­å¿ƒ|é†«é™¢|å…¬åœ’|å­¸æ ¡|é£¯åº—|è¶…å¸‚|ç™¾è²¨|åœ–æ›¸é¤¨|æ©Ÿå ´|é«”è‚²é¤¨|æ·é‹ç«™|ç«è»Šç«™|å•†å ´|å°åŒ—è»Šç«™|å·¥å­¸å¤§æ¨“|å¤§æ¨“|æ—©é¤åº—)\"\n",
        "    # æŠ“ã€Œ2~8å­—ã€+é—œéµå­—ï¼Œå¦‚ã€Œå°åŒ—è»Šç«™ã€ã€ã€Œä¿¡ç¾©å¤§æ¨“ã€\n",
        "    loc_match = re.search(r\"([\\u4e00-\\u9fa5]{2,8}\" + location_keywords + \")\", sentence)\n",
        "    if loc_match:\n",
        "        return loc_match.group(0)\n",
        "    return \"\"\n",
        "\n",
        "def clean_event_desc(sentence, time_str, location):\n",
        "    desc = sentence\n",
        "    if time_str:\n",
        "        desc = desc.replace(time_str, \"\")\n",
        "    if location:\n",
        "        desc = desc.replace(location, \"\")\n",
        "    # å»æ‰ã€Œæˆ‘åœ¨ã€ã€Œè¦åˆ°ã€ã€ŒåƒåŠ ã€ç­‰åŠ©è©/å‹•è©å‰ç¶´\n",
        "    desc = re.sub(r\"^[æˆ‘ä½ ä»–å¥¹åœ¨è¦å»åˆ°æ–¼åƒåŠ å‰å¾€]+\", \"\", desc)\n",
        "    desc = desc.strip(\"ï¼Œã€‚ \")\n",
        "    return desc\n"
      ],
      "metadata": {
        "id": "ksEaK5ZiYO0s"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ä¸‰ã€ä¸»æµç¨‹ (é›™æ¨¡å‹èåˆ) =====\n",
        "sentence = \"æˆ‘åœ¨6æœˆ10æ—¥ä¸‹åˆ3é»è¦åˆ°å°åŒ—è»Šç«™åƒåŠ è«–æ–‡å£è©¦\"\n",
        "\n",
        "# 1. transformers NER é æ¸¬\n",
        "ner_results = ner(sentence)\n",
        "\n",
        "# 2. HanLP é æ¸¬\n",
        "hanlp_time, hanlp_location = extract_by_hanlp(sentence)\n",
        "\n",
        "# 3. æ­£å‰‡æŠ“æ™‚é–“\n",
        "regex_time = extract_time_regex(sentence)\n",
        "\n",
        "# 4. NERæŠ“æ™‚é–“ã€åœ°é»\n",
        "ner_time = extract_time_ner(sentence, ner_results)\n",
        "ner_location = extract_location_ner(ner_results)\n"
      ],
      "metadata": {
        "id": "yWHzeGhlYUzG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== å››ã€æ¡ç”¨ã€Œæœ€ç©©å®šã€ä¾†æºï¼šå„ªå…ˆé †åº HanLP > æ­£å‰‡ > NER =====\n",
        "# æ™‚é–“\n",
        "time_str = hanlp_time or regex_time or ner_time\n",
        "# åœ°é»\n",
        "location = hanlp_location or ner_location\n",
        "\n",
        "# äº‹ä»¶æè¿°ï¼ˆå¾åŸæ–‡ç§»é™¤æ™‚é–“ã€åœ°é»ï¼‰\n",
        "event_desc = extract_event_desc(sentence, time_str, location)\n",
        "\n",
        "# è§£ææ™‚é–“\n",
        "parsed_time = dateparser.parse(time_str, languages=['zh'])"
      ],
      "metadata": {
        "id": "G0j3ylZAYWpq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== äº”ã€æœ€çµ‚è¼¸å‡º =====\n",
        "print(\"âœ… æ“·å–çµæœï¼š\")\n",
        "print(\"ğŸ•’ æ™‚é–“ï¼š\", parsed_time, \"ï½œåŸæ–‡ï¼š\", time_str)\n",
        "print(\"ğŸ“ åœ°é»ï¼š\", location)\n",
        "print(\"ğŸ“ äº‹ä»¶æè¿°ï¼š\", event_desc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOw6blalXZTr",
        "outputId": "786eb938-cac9-4bf6-81de-c31666ed7d21"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æ“·å–çµæœï¼š\n",
            "ğŸ•’ æ™‚é–“ï¼š None ï½œåŸæ–‡ï¼š ç¦®æ‹œäºŒ\n",
            "ğŸ“ åœ°é»ï¼š \n",
            "ğŸ“ äº‹ä»¶æè¿°ï¼š æˆ‘å€‘ä¸‹å»åƒæ—©é¤\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# è¼‰å…¥ HanLP\n",
        "hanlp_pipeline = hanlp.load('FINE_ELECTRA_SMALL_ZH')\n",
        "\n",
        "def extract_time_regex(sentence):\n",
        "    \"\"\"ç”¨æ­£å‰‡å¼è£œæ‰ä¸­æ–‡æ™‚é–“\"\"\"\n",
        "    patterns = [\n",
        "        r\"\\d{1,2}æœˆ\\d{1,2}æ—¥[ä¸Šä¸‹]åˆ\\d{1,2}é»åŠ?\",\n",
        "        r\"\\d{1,2}æœˆ\\d{1,2}æ—¥\\d{1,2}é»åŠ?\",\n",
        "        r\"\\d{1,2}æœˆ\\d{1,2}æ—¥\\d{1,2}é»\",\n",
        "        r\"\\d{1,2}æœˆ\\d{1,2}æ—¥\",\n",
        "        r\"[ä¸Šä¸‹]åˆ\\d{1,2}é»åŠ?\",\n",
        "        r\"\\d{1,2}é»åŠ?\",\n",
        "        r\"\\d{1,2}é»\",\n",
        "    ]\n",
        "    regex = \"|\".join(patterns)\n",
        "    match = re.search(regex, sentence)\n",
        "    if match:\n",
        "        return match.group()\n",
        "    return \"\"\n",
        "\n",
        "def normalize_time(time_str, base_year=None):\n",
        "    \"\"\"å°‡æ™‚é–“æ–‡å­—è½‰æˆ datetime\"\"\"\n",
        "    if not time_str:\n",
        "        return None\n",
        "    year = base_year or datetime.now().year\n",
        "    time_str = re.sub(r\"^(\\d{1,2})æœˆ\", f\"{year}å¹´\\\\1æœˆ\", time_str)\n",
        "    # è½‰æ›ä¸‹åˆã€æ™šä¸Šç­‰è©å½™\n",
        "    match = re.search(r\"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\\d{1,2})é»(åŠ)?\", time_str)\n",
        "    if match:\n",
        "        h = int(match.group(2))\n",
        "        if match.group(1) in [\"ä¸‹åˆ\", \"æ™šä¸Š\", \"å‚æ™š\"] and h < 12:\n",
        "            h += 12\n",
        "        elif match.group(1) == \"ä¸­åˆ\":\n",
        "            h = 12\n",
        "        elif match.group(1) == \"å‡Œæ™¨\" and h == 12:\n",
        "            h = 0\n",
        "        m = \"30\" if match.group(3) else \"00\"\n",
        "        time_str = re.sub(r\"(ä¸‹åˆ|æ™šä¸Š|å‚æ™š|ä¸­åˆ|å‡Œæ™¨|æ—©ä¸Š|ä¸Šåˆ)?(\\d{1,2})é»(åŠ)?\", f\"{h:02d}:{m}\", time_str)\n",
        "    dt = dateparser.parse(time_str, languages=['zh'])\n",
        "    return dt\n",
        "\n",
        "def extract_location(sentence, hanlp_out):\n",
        "    \"\"\"åœ°é»æŠ½å–ï¼šHanLP + è‡ªè¨‚é—œéµå­—å¾Œç¶´\"\"\"\n",
        "    if 'location' in hanlp_out and hanlp_out['location']:\n",
        "        return hanlp_out['location'][0][0]\n",
        "    location_keywords = r\"(è»Šç«™|å¤§æ¨“|é¤¨|ä¸­å¿ƒ|é†«é™¢|å…¬åœ’|å­¸æ ¡|é£¯åº—|è¶…å¸‚|ç™¾è²¨|åœ–æ›¸é¤¨|æ©Ÿå ´|é«”è‚²é¤¨|æ·é‹ç«™|ç«è»Šç«™|å•†å ´|å°åŒ—è»Šç«™)\"\n",
        "    loc_match = re.search(r\"[\\u4e00-\\u9fa5]{2,10}\" + location_keywords, sentence)\n",
        "    if loc_match:\n",
        "        return loc_match.group(0)\n",
        "    return \"\"\n",
        "\n",
        "def clean_event_desc(sentence, time_str, location):\n",
        "    \"\"\"ç§»é™¤æ™‚é–“èˆ‡åœ°é»ï¼Œç•™ä¸‹äº‹ä»¶æè¿°\"\"\"\n",
        "    desc = sentence\n",
        "    if time_str:\n",
        "        desc = desc.replace(time_str, \"\")\n",
        "    if location:\n",
        "        desc = desc.replace(location, \"\")\n",
        "    desc = re.sub(r\"^[æˆ‘ä½ ä»–å¥¹åœ¨è¦å»åˆ°æ–¼åƒåŠ å‰å¾€]+\", \"\", desc)\n",
        "    return desc.strip(\"ï¼Œã€‚ \")\n",
        "\n",
        "def extract_event(sentence):\n",
        "    \"\"\"ä¸»æŠ½å–æµç¨‹ï¼šæ™‚é–“ã€åœ°é»ã€æè¿°\"\"\"\n",
        "    hanlp_out = hanlp_pipeline(sentence)\n",
        "\n",
        "    time_str = hanlp_out['time'][0][0] if 'time' in hanlp_out and hanlp_out['time'] else extract_time_regex(sentence)\n",
        "    parsed_time = normalize_time(time_str)\n",
        "\n",
        "    location = extract_location(sentence, hanlp_out)\n",
        "    event_desc = clean_event_desc(sentence, time_str, location)\n",
        "\n",
        "    return {\n",
        "        \"æ™‚é–“åŸæ–‡\": time_str,\n",
        "        \"æ™‚é–“è§£æ\": parsed_time,\n",
        "        \"åœ°é»\": location,\n",
        "        \"äº‹ä»¶æè¿°\": event_desc\n",
        "    }\n",
        "\n",
        "# ==== æ¸¬è©¦ ====\n",
        "sentence = \"æˆ‘åœ¨6æœˆ10æ—¥ä¸‹åˆ3é»è¦åˆ°å°åŒ—è»Šç«™åƒåŠ è«–æ–‡å£è©¦\"\n",
        "event_info = extract_event(sentence)\n",
        "\n",
        "print(\"âœ… æ“·å–çµæœï¼š\")\n",
        "print(\"ğŸ•’ æ™‚é–“ï¼š\", event_info[\"æ™‚é–“è§£æ\"], \"ï½œåŸæ–‡ï¼š\", event_info[\"æ™‚é–“åŸæ–‡\"])\n",
        "print(\"ğŸ“ åœ°é»ï¼š\", event_info[\"åœ°é»\"])\n",
        "print(\"ğŸ“ äº‹ä»¶æè¿°ï¼š\", event_info[\"äº‹ä»¶æè¿°\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpWw6lctoHXQ",
        "outputId": "9f7c9e1c-c848-461d-cd2a-2b5c0f02d5b6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æ“·å–çµæœï¼š\n",
            "ğŸ•’ æ™‚é–“ï¼š 2025-06-10 15:00:00 ï½œåŸæ–‡ï¼š 6æœˆ10æ—¥ä¸‹åˆ3é»\n",
            "ğŸ“ åœ°é»ï¼š é»è¦åˆ°å°åŒ—è»Šç«™\n",
            "ğŸ“ äº‹ä»¶æè¿°ï¼š å°åŒ—è»Šç«™åƒåŠ è«–æ–‡å£è©¦\n"
          ]
        }
      ]
    }
  ]
}